{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "import gym_snake\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, \\\n",
    "    Convolution2D, Permute, Input, Lambda\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import model_from_config\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'snake-v0'  # Environment name\n",
    "FRAME_WIDTH = 84  # Resized frame width\n",
    "FRAME_HEIGHT = 84  # Resized frame height\n",
    "INPUT_SHAPE = (FRAME_WIDTH, FRAME_HEIGHT)\n",
    "WINDOW_LENGTH = 4  # Number of most recent frames to produce the input to the network (WINDOW LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_STEPS = 1_000_005\n",
    "\n",
    "EXPLORATION_STEPS = 500_005  # Number of steps over which the initial value # of epsilon is linearly annealed to its final value\n",
    "INITIAL_EPSILON = 1.0  # Initial value of epsilon in epsilon-greedy\n",
    "FINAL_EPSILON = 0.1  # Final value of epsilon in epsilon-greedy\n",
    "\n",
    "OBSERVE = 20_000  # Number of steps to populate the replay memory before training starts\n",
    "NUM_REPLAY_MEMORY = 400_000  # Number of replay memory the agent uses for training\n",
    "BATCH_SIZE = 32  # Mini batch size\n",
    "TARGET_UPDATE_INTERVAL = 10_000  # The frequency with which the target network is updated\n",
    "TRAIN_INTERVAL = 4  # The agent selects 4 actions between successive updates\n",
    "\n",
    "LEARNING_RATE = 0.00025  # Learning rate used by optimizer\n",
    "GAMMA = 0.99  # Discount factor\n",
    "\n",
    "SAVE_INTERVAL = 200_000  # The frequency with which the network is saved\n",
    "NO_OP_STEPS = 7  # Maximum number of \"do nothing\" actions to be performed by the agent at the start of an episode\n",
    "\n",
    "SAVE_NETWORK_PATH = 'saved_networks/' + ENV_NAME\n",
    "SAVE_SUMMARY_PATH = 'summary/' + ENV_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    env = gym.make(ENV_NAME)\n",
    "    env.n_foods = 3\n",
    "    env.grid_size = [20, 20]\n",
    "    env.unit_size = 10\n",
    "    env.unit_gap = 1\n",
    "    env.wall = True\n",
    "    env.random_init = True\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Size:  [20 20]\nImage shape before pre-processing:  (200, 200, 3)\nImage shape after pre-processing:  (84, 84)\nNo. of actions:  4\n\nBefore Preprocessing:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nAfter Preprocessing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n/home/ankur/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAABUCAAAAAA5AE8dAAAA50lEQVR4nO3VsQnCUBDG8X/ETsUNBBERwU6EzOAAdlZOYGEREUEQQirdwcYJnMOANpnGTjARvOgFfMl9ZXL84H15XLwL+qkVYBpaabQOsAc2H0cDIJSjN9FoLJoC5zo9i0bnQ445UFlO4knHOpVlMSJSR5OEvmyylJ0Kzw549uMz1NBKotmFcoV2Vxtdg7/9DXW50wM01dFBbmMKvOx6lzvNHz/9wH58+vniQwVx6lpm4s7xC0HtnupHeE/v0OpooyGMl2K0dJ3uoKGO9uQiLnX6L0v6mRlMVu9euHN8W9KGGmqooVVDH07HF3bC+BcWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=84x84 at 0x7F72811403C8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env()\n",
    "x_t = env.reset()\n",
    "\n",
    "# Controller\n",
    "game_controller = env.controller\n",
    "# Grid\n",
    "grid_object = game_controller.grid\n",
    "grid_pixels = grid_object.grid\n",
    "print('Grid Size: ', grid_object.grid_size)\n",
    "# Snake(s)\n",
    "snakes_array = game_controller.snakes\n",
    "snake_object1 = snakes_array[0]\n",
    "\n",
    "state_shape = grid_pixels.shape\n",
    "print('Image shape before pre-processing: ', state_shape)\n",
    "print('Image shape after pre-processing: ', (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "nb_actions = env.action_space.n\n",
    "print('No. of actions: ', nb_actions)\n",
    "\n",
    "print('\\nBefore Preprocessing:')\n",
    "env.render()\n",
    "\n",
    "print('\\nAfter Preprocessing:')\n",
    "\n",
    "processed_image = np.uint8(resize(rgb2gray(x_t), (FRAME_WIDTH, FRAME_HEIGHT)) * 255)\n",
    "img = Image.fromarray(processed_image)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE:  (4, 84, 84)\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\npermute_1 (Permute)          (None, 84, 84, 4)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 20, 20, 32)        8224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 20, 20, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 9, 9, 64)          32832     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               1606144   \n_________________________________________________________________\nactivation_4 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 2052      \n_________________________________________________________________\nactivation_5 (Activation)    (None, 4)                 0         \n=================================================================\nTotal params: 1,686,180\nTrainable params: 1,686,180\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE:  (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "\n",
    "\n",
    "def r(raw):\n",
    "    raw = [f.reshape((1,) + INPUT_SHAPE) for f in raw]\n",
    "    raw = np.asarray(raw).reshape(input_shape)\n",
    "    raw = np.expand_dims(raw, axis=0)\n",
    "    return raw\n",
    "\n",
    "\n",
    "def process_observation(observation):\n",
    "    assert observation.ndim == 3  # (height, width, channel)\n",
    "    img = Image.fromarray(observation)\n",
    "    img = img.resize(INPUT_SHAPE).convert('L')  # resize and convert to grayscale\n",
    "    processed_observation = np.array(img)\n",
    "    assert processed_observation.shape == INPUT_SHAPE\n",
    "    return processed_observation.astype('uint8') / 255.  # saves storage in experience memory\n",
    "\n",
    "\n",
    "def huber_loss(y_true, y_pred):\n",
    "    return tf.losses.huber_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        # (width, height, channels)\n",
    "        model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "    elif K.image_dim_ordering() == 'th':\n",
    "        # (channels, width, height)\n",
    "        model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "    else:\n",
    "        raise RuntimeError('Unknown image_dim_ordering.')\n",
    "    print('INPUT SHAPE: ', input_shape)\n",
    "    model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_actions))\n",
    "    model.add(Activation('linear'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "model.compile(loss=huber_loss, optimizer=Adam(lr=LEARNING_RATE), metrics=['mae'])\n",
    "\n",
    "target_model = get_model()\n",
    "target_model.compile(loss=huber_loss, optimizer=Adam(lr=LEARNING_RATE), metrics=['mae'])\n",
    "\n",
    "\n",
    "def get_action(state, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(env.action_space.n)\n",
    "    if random.random() < 0.5:\n",
    "        act_values = model.predict(r(state))\n",
    "    else:\n",
    "        act_values = target_model.predict(r(state))\n",
    "    return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "def get_test_action(state, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(env.action_space.n)\n",
    "    act_values = model.predict(r(state))\n",
    "    return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "def update_model():\n",
    "    minibatch = random.sample(memory, BATCH_SIZE)\n",
    "    total_loss = 0.\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            best_action = np.argmax(model.predict(r(next_state))[0])\n",
    "            target = (reward + GAMMA * target_model.predict(r(next_state))[0][best_action])\n",
    "        target_f = model.predict(r(state))\n",
    "        target_f[0][action] = target\n",
    "        h = model.fit(r(state), target_f, epochs=1, verbose=0)\n",
    "        total_loss += h.history['loss'][0]\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def update_target():\n",
    "    minibatch = random.sample(memory, BATCH_SIZE)\n",
    "    total_loss = 0.\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            best_action = np.argmax(target_model.predict(r(next_state))[0])\n",
    "            target = (reward + GAMMA * model.predict(r(next_state))[0][best_action])\n",
    "        target_f = target_model.predict(r(state))\n",
    "        target_f[0][action] = target\n",
    "        h = model.fit(r(state), target_f, epochs=1, verbose=0)\n",
    "        total_loss += h.history['loss'][0]\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def replay():\n",
    "    if random.random() > 0.5:\n",
    "        return update_target()\n",
    "    else:\n",
    "        return update_model()\n",
    "\n",
    "\n",
    "def setup_summary():\n",
    "    episode_total_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Total_Reward/Episode', episode_total_reward)\n",
    "    episode_avg_max_q = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Average_Max_Q/Episode', episode_avg_max_q)\n",
    "    episode_duration = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Duration/Episode', episode_duration)\n",
    "    episode_avg_loss = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Average_Loss/Episode', episode_avg_loss)\n",
    "    epsilon = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Epsilon/Episode', epsilon)\n",
    "    curr_time_step = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Steps/Episode', curr_time_step)\n",
    "\n",
    "    summary_vars = [episode_total_reward, episode_avg_max_q, episode_duration, episode_avg_loss, epsilon,\n",
    "                    curr_time_step]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op\n",
    "# def get_initial_state(self, observation):\n",
    "#     processed_observation = np.uint8(resize(rgb2gray(observation), (FRAME_WIDTH, FRAME_HEIGHT)) * 255)\n",
    "#     state = [processed_observation for _ in range(WINDOW_LENGTH)]\n",
    "#     return np.stack(state, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\npermute_1 (Permute)          (None, 84, 84, 4)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 20, 20, 32)        8224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 20, 20, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 9, 9, 64)          32832     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 7, 7, 64)          36928     \n_________________________________________________________________\nactivation_11 (Activation)   (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 512)               1606144   \n_________________________________________________________________\nactivation_12 (Activation)   (None, 512)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 4)                 2052      \n_________________________________________________________________\nactivation_13 (Activation)   (None, 4)                 0         \n=================================================================\nTotal params: 1,686,180\nTrainable params: 1,686,180\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('snake2 transfer learning/snake1_best.h5f')\n",
    "\n",
    "for i in range(7):\n",
    "    model.pop()\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ankur/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\nInstructions for updating:\nUse `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/1000005 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 7/1000005 [00:00<4:11:05, 66.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 23/1000005 [00:00<3:27:55, 80.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 38/1000005 [00:00<2:59:36, 92.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 52/1000005 [00:00<2:42:32, 102.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      1 / TIMESTEP:       36 / DURATION:    37 / EPSILON: 1.00000 / TOTAL_REWARD:   2 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      2 / TIMESTEP:       47 / DURATION:    11 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 67/1000005 [00:00<2:28:48, 112.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 87/1000005 [00:00<2:09:27, 128.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 108/1000005 [00:00<1:54:55, 145.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 130/1000005 [00:00<1:43:58, 160.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      3 / TIMESTEP:       95 / DURATION:    48 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.9375 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      4 / TIMESTEP:       96 / DURATION:     1 / EPSILON: 1.00000 / TOTAL_REWARD:   0 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      5 / TIMESTEP:      132 / DURATION:    36 / EPSILON: 1.00000 / TOTAL_REWARD:   1 / AVG_MAX_Q: 2.5278 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 148/1000005 [00:00<1:42:25, 162.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 170/1000005 [00:01<1:35:05, 175.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      6 / TIMESTEP:      136 / DURATION:     4 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 189/1000005 [00:01<1:37:42, 170.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 211/1000005 [00:01<1:31:51, 181.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 231/1000005 [00:01<1:30:16, 184.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 253/1000005 [00:01<1:26:45, 192.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      7 / TIMESTEP:      220 / DURATION:    84 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.5714 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 273/1000005 [00:01<1:31:58, 181.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      8 / TIMESTEP:      262 / DURATION:    42 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.9524 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      9 / TIMESTEP:      269 / DURATION:     7 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.5714 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     10 / TIMESTEP:      272 / DURATION:     3 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     11 / TIMESTEP:      283 / DURATION:    11 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 292/1000005 [00:01<1:41:19, 164.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 310/1000005 [00:01<1:43:40, 160.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 327/1000005 [00:01<1:43:19, 161.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 344/1000005 [00:02<1:42:57, 161.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 361/1000005 [00:02<1:42:53, 161.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     12 / TIMESTEP:      343 / DURATION:    60 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.0500 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 379/1000005 [00:02<1:41:49, 163.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 396/1000005 [00:02<1:45:36, 157.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 415/1000005 [00:02<1:40:39, 165.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     13 / TIMESTEP:      387 / DURATION:    44 / EPSILON: 1.00000 / TOTAL_REWARD:   2 / AVG_MAX_Q: 1.0682 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 434/1000005 [00:02<1:36:54, 171.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 455/1000005 [00:02<1:32:38, 179.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 475/1000005 [00:02<1:30:33, 183.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     14 / TIMESTEP:      445 / DURATION:    58 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.7069 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     15 / TIMESTEP:      456 / DURATION:    11 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     16 / TIMESTEP:      467 / DURATION:    11 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 0.5455 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     17 / TIMESTEP:      473 / DURATION:     6 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 3.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 494/1000005 [00:02<1:31:02, 182.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 515/1000005 [00:03<1:28:01, 189.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     18 / TIMESTEP:      506 / DURATION:    33 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.0303 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3be6e50bc273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mduration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtotal_q_max\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "memory = deque(maxlen=NUM_REPLAY_MEMORY)\n",
    "state = deque(maxlen=WINDOW_LENGTH)\n",
    "\n",
    "env = get_env()\n",
    "observation = env.reset()\n",
    "observation = process_observation(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "\n",
    "current = [observation for _ in range(WINDOW_LENGTH)]\n",
    "previous = [observation for _ in range(WINDOW_LENGTH)]\n",
    "\n",
    "# Parameters used for summary\n",
    "total_reward = 0.\n",
    "total_q_max = 0.\n",
    "total_loss = 0.\n",
    "duration = 0\n",
    "episode = 0\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter(SAVE_SUMMARY_PATH, sess.graph)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "epsilon = INITIAL_EPSILON\n",
    "\n",
    "for t in tqdm(range(NUM_STEPS)):\n",
    "    action = get_action(current, epsilon)\n",
    "\n",
    "    observation, reward, terminal, _ = env.step(int(action))\n",
    "    observation = process_observation(observation)\n",
    "    total_reward += reward\n",
    "    duration += 1\n",
    "\n",
    "    total_q_max += np.argmax(model.predict(r(state)))\n",
    "    state.append(observation)\n",
    "\n",
    "    # Remember\n",
    "    current = list(state)\n",
    "    memory.append((previous, action, reward, current, terminal))\n",
    "    previous = current\n",
    "\n",
    "    if t > OBSERVE:\n",
    "        # Train\n",
    "        if t % TRAIN_INTERVAL == 0:\n",
    "            total_loss += replay()\n",
    "        \n",
    "        # Save Weights Interval\n",
    "        if t % SAVE_INTERVAL == 0:\n",
    "            model.save_weights((SAVE_NETWORK_PATH + '/snake2_tl_{}.h5').format(t))\n",
    "    \n",
    "        # Update Target Network\n",
    "        if t % TARGET_UPDATE_INTERVAL == 0:\n",
    "            target_model.set_weights(model.get_weights())\n",
    "        \n",
    "        # Exploration Rate Decay\n",
    "        if epsilon > FINAL_EPSILON:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORATION_STEPS\n",
    "\n",
    "    # End of episode\n",
    "    if terminal:\n",
    "        # Writing Summary Log\n",
    "        avg_q = total_q_max / float(duration)\n",
    "        avg_loss = total_loss / (float(duration) / float(TRAIN_INTERVAL))\n",
    "        if t >= OBSERVE:\n",
    "            stats = [total_reward, avg_q, duration, avg_loss, float(epsilon), float(t)]\n",
    "\n",
    "            for i in range(len(stats)):\n",
    "                sess.run(update_ops[i], feed_dict={\n",
    "                    summary_placeholders[i]: float(stats[i])\n",
    "                })\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, episode + 1)\n",
    "\n",
    "        # Debug\n",
    "        if t < OBSERVE:\n",
    "            mode = 'random'\n",
    "        elif OBSERVE <= t < OBSERVE + EXPLORATION_STEPS:\n",
    "            mode = 'explore'\n",
    "        else:\n",
    "            mode = 'exploit'\n",
    "        print(\n",
    "            'EPISODE: {0:6d} / TIMESTEP: {1:8d} / DURATION: {2:5d} /'\n",
    "            ' EPSILON: {3:.5f} / TOTAL_REWARD: {4:3.0f} / '\n",
    "            'AVG_MAX_Q: {5:2.4f} / AVG_LOSS: {6:.5f} / MODE: {7}'.format(\n",
    "                episode + 1, t, duration, epsilon,\n",
    "                total_reward, avg_q, avg_loss, mode))\n",
    "\n",
    "        total_reward = 0.\n",
    "        total_q_max = 0.\n",
    "        total_loss = 0.\n",
    "        duration = 0\n",
    "        episode += 1\n",
    "\n",
    "        observation = env.reset()\n",
    "        for _ in range(random.randint(1, NO_OP_STEPS)):\n",
    "            observation, _, terminal, _ = env.step(env.action_space.sample())  # Do nothing\n",
    "            if terminal:\n",
    "                observation = env.reset()\n",
    "                break\n",
    "        observation = process_observation(observation)\n",
    "        state = deque(maxlen=WINDOW_LENGTH)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        current = [observation for i in range(4)]\n",
    "        previous = [observation for i in range(4)]\n",
    "\n",
    "model.save_weights(SAVE_NETWORK_PATH + '/snake2_tl_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 10%|█         | 1/10 [00:01<00:12,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [00:01<00:08,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [00:01<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 96\n2.0 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [00:02<00:05,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [00:04<00:05,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [00:05<00:04,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [00:06<00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [00:06<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [00:07<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 10/10 [00:08<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "for e in tqdm(range(10)):\n",
    "    state = deque(maxlen=WINDOW_LENGTH)\n",
    "    env = get_env()\n",
    "    observation = env.reset()\n",
    "    observation = process_observation(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "\n",
    "    current = [observation for _ in range(WINDOW_LENGTH)]\n",
    "\n",
    "    total_reward = 0.\n",
    "    duration = 0\n",
    "    episode = 0\n",
    "\n",
    "    terminal = False\n",
    "    while not terminal:\n",
    "        action = get_test_action(current, 0.)\n",
    "        # env.render()\n",
    "        observation, reward, terminal, _ = env.step(int(action))\n",
    "        observation = process_observation(observation)\n",
    "        total_reward += reward\n",
    "        duration += 1\n",
    "\n",
    "        state.append(observation)\n",
    "\n",
    "        # Remember\n",
    "        current = list(state)\n",
    "\n",
    "        if duration >= 600:\n",
    "            print(duration)\n",
    "            break\n",
    "\n",
    "    print(total_reward, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
