{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import gym\n",
    "import gym_snake\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, \\\n",
    "    Convolution2D, Permute, Input, Lambda\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import model_from_config\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'snake-v0'  # Environment name\n",
    "FRAME_WIDTH = 84  # Resized frame width\n",
    "FRAME_HEIGHT = 84  # Resized frame height\n",
    "INPUT_SHAPE = (FRAME_WIDTH, FRAME_HEIGHT)\n",
    "WINDOW_LENGTH = 4  # Number of most recent frames to produce the input to the network (WINDOW LENGTH)\n",
    "\n",
    "NUM_STEPS = 2_000_005\n",
    "\n",
    "EXPLORATION_STEPS = 1_000_005  # Number of steps over which the initial value # of epsilon is linearly annealed to its final value\n",
    "INITIAL_EPSILON = 1.0  # Initial value of epsilon in epsilon-greedy\n",
    "FINAL_EPSILON = 0.1  # Final value of epsilon in epsilon-greedy\n",
    "\n",
    "OBSERVE = 20_000  # Number of steps to populate the replay memory before training starts\n",
    "NUM_REPLAY_MEMORY = 400_000  # Number of replay memory the agent uses for training\n",
    "BATCH_SIZE = 32  # Mini batch size\n",
    "TARGET_UPDATE_INTERVAL = 10_000  # The frequency with which the target network is updated\n",
    "TRAIN_INTERVAL = 4  # The agent selects 4 actions between successive updates\n",
    "\n",
    "LEARNING_RATE = 0.00025  # Learning rate used by optimizer\n",
    "GAMMA = 0.99  # Discount factor\n",
    "\n",
    "SAVE_INTERVAL = 200_000  # The frequency with which the network is saved\n",
    "NO_OP_STEPS = 7  # Maximum number of \"do nothing\" actions to be performed by the agent at the start of an episode\n",
    "\n",
    "SAVE_NETWORK_PATH = 'saved_networks/' + ENV_NAME\n",
    "SAVE_SUMMARY_PATH = 'summary/' + ENV_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    env = gym.make(ENV_NAME)\n",
    "    env.n_foods = 3\n",
    "    env.grid_size = [20, 20]\n",
    "    env.unit_size = 10\n",
    "    env.unit_gap = 1\n",
    "    env.wall = True\n",
    "    env.random_init = True\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Size:  [20 20]\nImage shape before pre-processing:  (200, 200, 3)\nImage shape after pre-processing:  (84, 84)\nNo. of actions:  4\n\nBefore Preprocessing:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nAfter Preprocessing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankur/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n/home/ankur/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFQAAABUCAAAAAA5AE8dAAAA3klEQVR4nGPcxoAHVF5kYMCrADtgIl3LcDKUkYwgIwiGjvdpYigL8UorGRgY2qlt6EWiVQ7LMI3VZJhAdUMXE61yWIZpsg5DJ9UNvXWLQZU4lcMyTIn0O8NoIT1q6Kiho4aOGjpq6AgzFKU2vdLCwNCiQrmhQ8f7oz2+IWIoCa0+GFhyn4GhltqG3r9MSMXQCdPRdDpq6Kiho4aOGjqIDUWpox4sZ2CIl6KyoV+vMjB8p9zMIRSmlFZ8FxgYGAzQBPgpNdSLAW12xYuBwWLkhOlNBgYGdTQBntEWCvUBAPt0H3e3NU+oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=84x84 at 0x7FE1D1B06C18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = get_env()\n",
    "x_t = env.reset()\n",
    "\n",
    "# Controller\n",
    "game_controller = env.controller\n",
    "# Grid\n",
    "grid_object = game_controller.grid\n",
    "grid_pixels = grid_object.grid\n",
    "print('Grid Size: ', grid_object.grid_size)\n",
    "# Snake(s)\n",
    "snakes_array = game_controller.snakes\n",
    "snake_object1 = snakes_array[0]\n",
    "\n",
    "state_shape = grid_pixels.shape\n",
    "print('Image shape before pre-processing: ', state_shape)\n",
    "print('Image shape after pre-processing: ', (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "nb_actions = env.action_space.n\n",
    "print('No. of actions: ', nb_actions)\n",
    "\n",
    "print('\\nBefore Preprocessing:')\n",
    "env.render()\n",
    "\n",
    "print('\\nAfter Preprocessing:')\n",
    "\n",
    "processed_image = np.uint8(resize(rgb2gray(x_t), (FRAME_WIDTH, FRAME_HEIGHT)) * 255)\n",
    "img = Image.fromarray(processed_image)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE:  (4, 84, 84)\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\npermute_1 (Permute)          (None, 84, 84, 4)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 20, 20, 32)        8224      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 20, 20, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 9, 9, 64)          32832     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 7, 7, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3136)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               1606144   \n_________________________________________________________________\nactivation_4 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 2052      \n_________________________________________________________________\nactivation_5 (Activation)    (None, 4)                 0         \n=================================================================\nTotal params: 1,686,180\nTrainable params: 1,686,180\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE:  (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
    "\n",
    "\n",
    "def r(raw):\n",
    "    raw = [f.reshape((1,) + INPUT_SHAPE) for f in raw]\n",
    "    raw = np.asarray(raw).reshape(input_shape)\n",
    "    raw = np.expand_dims(raw, axis=0)\n",
    "    return raw\n",
    "\n",
    "\n",
    "def process_observation(observation):\n",
    "    assert observation.ndim == 3  # (height, width, channel)\n",
    "    img = Image.fromarray(observation)\n",
    "    img = img.resize(INPUT_SHAPE).convert('L')  # resize and convert to grayscale\n",
    "    processed_observation = np.array(img)\n",
    "    assert processed_observation.shape == INPUT_SHAPE\n",
    "    return processed_observation.astype('uint8') / 255.  # saves storage in experience memory\n",
    "\n",
    "\n",
    "def huber_loss(y_true, y_pred):\n",
    "    return tf.losses.huber_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        # (width, height, channels)\n",
    "        model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "    elif K.image_dim_ordering() == 'th':\n",
    "        # (channels, width, height)\n",
    "        model.add(Permute((1, 2, 3), input_shape=input_shape))\n",
    "    else:\n",
    "        raise RuntimeError('Unknown image_dim_ordering.')\n",
    "    print('INPUT SHAPE: ', input_shape)\n",
    "    model.add(Convolution2D(32, (8, 8), strides=(4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (4, 4), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), strides=(1, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_actions))\n",
    "    model.add(Activation('linear'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())\n",
    "model.compile(loss=huber_loss, optimizer=Adam(lr=LEARNING_RATE), metrics=['mae'])\n",
    "\n",
    "target_model = get_model()\n",
    "target_model.compile(loss=huber_loss, optimizer=Adam(lr=LEARNING_RATE), metrics=['mae'])\n",
    "\n",
    "\n",
    "def get_action(state, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(env.action_space.n)\n",
    "    if random.random() < 0.5:\n",
    "        act_values = model.predict(r(state))\n",
    "    else:\n",
    "        act_values = target_model.predict(r(state))\n",
    "    return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "def get_test_action(state, epsilon):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(env.action_space.n)\n",
    "    act_values = model.predict(r(state))\n",
    "    return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "def update_model():\n",
    "    minibatch = random.sample(memory, BATCH_SIZE)\n",
    "    total_loss = 0.\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            best_action = np.argmax(model.predict(r(next_state))[0])\n",
    "            target = (reward + GAMMA * target_model.predict(r(next_state))[0][best_action])\n",
    "        target_f = model.predict(r(state))\n",
    "        target_f[0][action] = target\n",
    "        h = model.fit(r(state), target_f, epochs=1, verbose=0)\n",
    "        total_loss += h.history['loss'][0]\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def update_target():\n",
    "    minibatch = random.sample(memory, BATCH_SIZE)\n",
    "    total_loss = 0.\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            best_action = np.argmax(target_model.predict(r(next_state))[0])\n",
    "            target = (reward + GAMMA * model.predict(r(next_state))[0][best_action])\n",
    "        target_f = target_model.predict(r(state))\n",
    "        target_f[0][action] = target\n",
    "        h = model.fit(r(state), target_f, epochs=1, verbose=0)\n",
    "        total_loss += h.history['loss'][0]\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def replay():\n",
    "    if random.random() > 0.5:\n",
    "        return update_target()\n",
    "    else:\n",
    "        return update_model()\n",
    "\n",
    "\n",
    "def setup_summary():\n",
    "    episode_total_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Total_Reward/Episode', episode_total_reward)\n",
    "    episode_avg_max_q = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Average_Max_Q/Episode', episode_avg_max_q)\n",
    "    episode_duration = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Duration/Episode', episode_duration)\n",
    "    episode_avg_loss = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Average_Loss/Episode', episode_avg_loss)\n",
    "    epsilon = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Epsilon/Episode', epsilon)\n",
    "    curr_time_step = tf.Variable(0.)\n",
    "    tf.summary.scalar(ENV_NAME + '/Steps/Episode', curr_time_step)\n",
    "\n",
    "    summary_vars = [episode_total_reward, episode_avg_max_q, episode_duration, episode_avg_loss, epsilon,\n",
    "                    curr_time_step]\n",
    "    summary_placeholders = [tf.placeholder(tf.float32) for _ in range(len(summary_vars))]\n",
    "    update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in range(len(summary_vars))]\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    return summary_placeholders, update_ops, summary_op\n",
    "# def get_initial_state(self, observation):\n",
    "#     processed_observation = np.uint8(resize(rgb2gray(observation), (FRAME_WIDTH, FRAME_HEIGHT)) * 255)\n",
    "#     state = [processed_observation for _ in range(WINDOW_LENGTH)]\n",
    "#     return np.stack(state, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ankur/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\nInstructions for updating:\nUse `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/2000005 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 1/2000005 [00:00<64:53:10,  8.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 18/2000005 [00:00<46:26:58, 11.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 32/2000005 [00:00<33:45:16, 16.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 46/2000005 [00:00<24:52:01, 22.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 64/2000005 [00:00<18:23:53, 30.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 81/2000005 [00:00<13:51:33, 40.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 97/2000005 [00:00<10:45:02, 51.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 117/2000005 [00:00<8:22:18, 66.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      1 / TIMESTEP:       94 / DURATION:    95 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.3053 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      2 / TIMESTEP:      131 / DURATION:    37 / EPSILON: 1.00000 / TOTAL_REWARD:   5 / AVG_MAX_Q: 1.4595 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 135/2000005 [00:00<6:50:45, 81.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 154/2000005 [00:01<5:40:22, 97.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 173/2000005 [00:01<4:52:53, 113.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 193/2000005 [00:01<4:17:27, 129.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 213/2000005 [00:01<3:51:25, 144.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      3 / TIMESTEP:      173 / DURATION:    42 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.7381 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      4 / TIMESTEP:      194 / DURATION:    21 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.2857 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      5 / TIMESTEP:      211 / DURATION:    17 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.2353 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 232/2000005 [00:01<3:34:50, 155.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 253/2000005 [00:01<3:18:35, 167.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      6 / TIMESTEP:      213 / DURATION:     2 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 273/2000005 [00:01<3:15:11, 170.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      7 / TIMESTEP:      254 / DURATION:    41 / EPSILON: 1.00000 / TOTAL_REWARD:   2 / AVG_MAX_Q: 1.5610 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:      8 / TIMESTEP:      293 / DURATION:    39 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.0513 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 294/2000005 [00:01<3:05:49, 179.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 314/2000005 [00:01<3:02:19, 182.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 336/2000005 [00:01<2:53:57, 191.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 357/2000005 [00:02<2:51:43, 194.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 379/2000005 [00:02<2:47:18, 199.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:      9 / TIMESTEP:      354 / DURATION:    61 / EPSILON: 1.00000 / TOTAL_REWARD:   2 / AVG_MAX_Q: 1.8525 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     10 / TIMESTEP:      366 / DURATION:    12 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.0000 / AVG_LOSS: 0.00000 / MODE: random\nEPISODE:     11 / TIMESTEP:      384 / DURATION:    18 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 2.0556 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 400/2000005 [00:02<2:53:33, 192.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 420/2000005 [00:02<2:52:47, 192.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 440/2000005 [00:02<2:51:07, 194.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     12 / TIMESTEP:      403 / DURATION:    19 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.6316 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 460/2000005 [00:02<3:01:52, 183.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 481/2000005 [00:02<2:56:00, 189.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 502/2000005 [00:02<2:52:51, 192.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 523/2000005 [00:02<2:49:53, 196.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 544/2000005 [00:03<2:46:43, 199.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     13 / TIMESTEP:      507 / DURATION:   104 / EPSILON: 1.00000 / TOTAL_REWARD:  -1 / AVG_MAX_Q: 1.2115 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 565/2000005 [00:03<2:48:47, 197.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 585/2000005 [00:03<2:48:56, 197.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 607/2000005 [00:03<2:44:00, 203.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE:     14 / TIMESTEP:      569 / DURATION:    62 / EPSILON: 1.00000 / TOTAL_REWARD:   2 / AVG_MAX_Q: 1.0000 / AVG_LOSS: 0.00000 / MODE: random\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 628/2000005 [00:03<2:46:39, 199.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 650/2000005 [00:03<2:43:37, 203.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 671/2000005 [00:03<2:43:08, 204.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa002a0889ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mduration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtotal_q_max\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "memory = deque(maxlen=NUM_REPLAY_MEMORY)\n",
    "state = deque(maxlen=WINDOW_LENGTH)\n",
    "\n",
    "env = get_env()\n",
    "observation = env.reset()\n",
    "observation = process_observation(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "state.append(observation)\n",
    "\n",
    "current = [observation for _ in range(WINDOW_LENGTH)]\n",
    "previous = [observation for _ in range(WINDOW_LENGTH)]\n",
    "\n",
    "# Parameters used for summary\n",
    "total_reward = 0.\n",
    "total_q_max = 0.\n",
    "total_loss = 0.\n",
    "duration = 0\n",
    "episode = 0\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "summary_placeholders, update_ops, summary_op = setup_summary()\n",
    "summary_writer = tf.summary.FileWriter(SAVE_SUMMARY_PATH, sess.graph)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "epsilon = INITIAL_EPSILON\n",
    "\n",
    "for t in tqdm(range(NUM_STEPS)):\n",
    "    action = get_action(current, epsilon)\n",
    "\n",
    "    observation, reward, terminal, _ = env.step(int(action))\n",
    "    observation = process_observation(observation)\n",
    "    total_reward += reward\n",
    "    duration += 1\n",
    "\n",
    "    total_q_max += np.argmax(model.predict(r(state)))\n",
    "    state.append(observation)\n",
    "\n",
    "    # Remember\n",
    "    current = list(state)\n",
    "    memory.append((previous, action, reward, current, terminal))\n",
    "    previous = current\n",
    "\n",
    "    if t > OBSERVE:\n",
    "        # Train\n",
    "        if t % TRAIN_INTERVAL == 0:\n",
    "            total_loss += replay()\n",
    "        \n",
    "        # Save Weights Interval\n",
    "        if t % SAVE_INTERVAL == 0:\n",
    "            model.save_weights((SAVE_NETWORK_PATH + '/snake2_{}.h5').format(t))\n",
    "    \n",
    "        # Update Target Network\n",
    "        if t % TARGET_UPDATE_INTERVAL == 0:\n",
    "            target_model.set_weights(model.get_weights())\n",
    "        \n",
    "        # Exploration Rate Decay\n",
    "        if epsilon > FINAL_EPSILON:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORATION_STEPS\n",
    "\n",
    "    # End of episode\n",
    "    if terminal:\n",
    "        # Writing Summary Log\n",
    "        avg_q = total_q_max / float(duration)\n",
    "        avg_loss = total_loss / (float(duration) / float(TRAIN_INTERVAL))\n",
    "        if t >= OBSERVE:\n",
    "            stats = [total_reward, avg_q, duration, avg_loss, float(epsilon), float(t)]\n",
    "\n",
    "            for i in range(len(stats)):\n",
    "                sess.run(update_ops[i], feed_dict={\n",
    "                    summary_placeholders[i]: float(stats[i])\n",
    "                })\n",
    "            summary_str = sess.run(summary_op)\n",
    "            summary_writer.add_summary(summary_str, episode + 1)\n",
    "\n",
    "        # Debug\n",
    "        if t < OBSERVE:\n",
    "            mode = 'random'\n",
    "        elif OBSERVE <= t < OBSERVE + EXPLORATION_STEPS:\n",
    "            mode = 'explore'\n",
    "        else:\n",
    "            mode = 'exploit'\n",
    "        print(\n",
    "            'EPISODE: {0:6d} / TIMESTEP: {1:8d} / DURATION: {2:5d} /'\n",
    "            ' EPSILON: {3:.5f} / TOTAL_REWARD: {4:3.0f} / '\n",
    "            'AVG_MAX_Q: {5:2.4f} / AVG_LOSS: {6:.5f} / MODE: {7}'.format(\n",
    "                episode + 1, t, duration, epsilon,\n",
    "                total_reward, avg_q, avg_loss, mode))\n",
    "\n",
    "        total_reward = 0.\n",
    "        total_q_max = 0.\n",
    "        total_loss = 0.\n",
    "        duration = 0\n",
    "        episode += 1\n",
    "\n",
    "        observation = env.reset()\n",
    "        for _ in range(random.randint(1, NO_OP_STEPS)):\n",
    "            observation, _, terminal, _ = env.step(env.action_space.sample())  # Do nothing\n",
    "            if terminal:\n",
    "                observation = env.reset()\n",
    "                break\n",
    "        observation = process_observation(observation)\n",
    "        state = deque(maxlen=WINDOW_LENGTH)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        state.append(observation)\n",
    "        current = [observation for i in range(4)]\n",
    "        previous = [observation for i in range(4)]\n",
    "\n",
    "model.save_weights(SAVE_NETWORK_PATH + '/snake2_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 10%|█         | 1/10 [00:01<00:12,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 20%|██        | 2/10 [00:01<00:08,  1.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 30%|███       | 3/10 [00:01<00:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 96\n2.0 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 40%|████      | 4/10 [00:02<00:05,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 50%|█████     | 5/10 [00:04<00:05,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 60%|██████    | 6/10 [00:05<00:04,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 70%|███████   | 7/10 [00:06<00:02,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 80%|████████  | 8/10 [00:06<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r 90%|█████████ | 9/10 [00:07<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r100%|██████████| 10/10 [00:08<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "for e in tqdm(range(10)):\n",
    "    state = deque(maxlen=WINDOW_LENGTH)\n",
    "    env = get_env()\n",
    "    observation = env.reset()\n",
    "    observation = process_observation(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "    state.append(observation)\n",
    "\n",
    "    current = [observation for _ in range(WINDOW_LENGTH)]\n",
    "\n",
    "    total_reward = 0.\n",
    "    duration = 0\n",
    "    episode = 0\n",
    "\n",
    "    terminal = False\n",
    "    while not terminal:\n",
    "        action = get_test_action(current, 0.)\n",
    "        # env.render()\n",
    "        observation, reward, terminal, _ = env.step(int(action))\n",
    "        observation = process_observation(observation)\n",
    "        total_reward += reward\n",
    "        duration += 1\n",
    "\n",
    "        state.append(observation)\n",
    "\n",
    "        # Remember\n",
    "        current = list(state)\n",
    "\n",
    "        if duration >= 600:\n",
    "            print(duration)\n",
    "            break\n",
    "\n",
    "    print(total_reward, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
